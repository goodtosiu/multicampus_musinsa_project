import os
import csv
import json
import time
import random
import re
from curl_cffi import requests
from bs4 import BeautifulSoup

# SQLAlchemy
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError

# ì‚¬ìš©ìì˜ DB Client ëª¨ë“ˆ (ê°™ì€ í´ë”ì— db_client.pyê°€ ìˆì–´ì•¼ í•¨)
from db_client import RDSClient

# ==========================================
# 1. í™˜ê²½ ì„¤ì • ë° DB ì´ˆê¸°í™”
# ==========================================
rds = RDSClient()

# í…Œì´ë¸” ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë™ì  ì¿¼ë¦¬ ìƒì„±ìš©)
cols_result = rds.execute("SHOW COLUMNS FROM product_bottom")
if not cols_result:
    print("âŒ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. DB ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
    exit()

db_cols = [row['Field'] for row in cols_result]
placeholders = ", ".join([f":{col}" for col in db_cols])
# INSERT êµ¬ë¬¸ ë¯¸ë¦¬ ìƒì„±
insert_sql = f"INSERT IGNORE INTO product_bottom ({', '.join(db_cols)}) VALUES ({placeholders})"

# ==========================================
# 2. CSV íŒŒì¼ ë¡œë“œ
# ==========================================
goods_ids = []
csv_filename = "musinsa_bottom_ids.csv"

try:
    with open(csv_filename, newline="", encoding="utf-8") as f:
        reader = csv.reader(f)
        next(reader) # í—¤ë” ê±´ë„ˆë›°ê¸°
        for row in reader:
            if row:
                goods_ids.append(row[0])
except FileNotFoundError:
    print(f"âŒ '{csv_filename}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# ==========================================
# 3. ì‹œì‘ ìœ„ì¹˜ ê³„ì‚° (ì´ì–´í•˜ê¸°)
# ==========================================
cnt_result = rds.execute("SELECT COUNT(*) as cnt FROM product_top")
saved_count = cnt_result[0]['cnt'] if cnt_result else 0

start_index = 0 # ì´ë¯¸ ì €ì¥ëœ ê°œìˆ˜ë§Œí¼ ê±´ë„ˆë›°ê³  ì‹œì‘
total_count = cnt_result # ëª©í‘œ ìˆ˜ì§‘ ê°œìˆ˜ (í•„ìš”ì‹œ ìˆ˜ì •)

# ë²”ìœ„ ë³´ì •
if total_count > len(goods_ids):
    total_count = len(goods_ids)

print(f"ğŸ“Š ì „ì²´ ID: {len(goods_ids)}ê°œ / ì´ë¯¸ ì €ì¥ë¨: {saved_count}ê°œ")
print(f"ğŸš€ ê¸ˆì¼ ì‘ì—… êµ¬ê°„: {start_index}ë²ˆë¶€í„° {total_count}ë²ˆê¹Œì§€ (ì´ {total_count - start_index}ê°œ)")

# ==========================================
# 4. í—¬í¼ í•¨ìˆ˜ ì •ì˜
# ==========================================

def create_session():
    """ìƒˆë¡œìš´ ì„¸ì…˜ì„ ìƒì„±í•˜ê³  í—¤ë”ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    s = requests.Session(impersonate="chrome")
    s.headers.update({
        "Referer": "https://www.musinsa.com/",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7"
    })
    return s

def smart_sleep():
    """
    [í„°ë³´ ëª¨ë“œ] ë¹ ë¥´ì§€ë§Œ ê¸°ê³„ì ì¸ íŒ¨í„´ì€ í”¼í•˜ëŠ” ëŒ€ê¸° ë¡œì§
    """
    prob = random.random() # 0.0 ~ 1.0 ë‚œìˆ˜

    if prob < 0.90:  
        # [90%] ê³ ì† ì£¼í–‰: 0.6ì´ˆ ~ 1.3ì´ˆ
        delay = random.uniform(0.2, 0.6)
        mode = "âš¡ë¹ ë¦„"
    elif prob < 0.99: 
        # [9%] ì ê¹ ìˆ¨ê³ ë¥´ê¸°: 2ì´ˆ ~ 3ì´ˆ
        delay = random.uniform(1.0, 1.6)
        mode = "ğŸ§˜ìˆ¨ê³ ë¥´ê¸°"
    else: 
        # [1%] ì•„ì£¼ ê°€ë” ë©ë•Œë¦¬ê¸°: 4ì´ˆ ~ 6ì´ˆ (íŒ¨í„´ ëŠê¸°ìš©)
        delay = random.uniform(4.0, 5.0)
        mode = "â˜•ì ê¹íœ´ì‹"
    
    print(f"   ğŸ’¤ [{mode}] {delay:.2f}ì´ˆ...", end="", flush=True)
    time.sleep(delay)

# ==========================================
# 5. ë©”ì¸ í¬ë¡¤ë§ ë£¨í”„
# ==========================================
session = create_session()

for idx in range(start_index, total_count):
    gid = goods_ids[idx]

    # [ëŒ€ê¸°] ìŠ¤ë§ˆíŠ¸ ìŠ¬ë¦½ ì ìš©
    smart_sleep()
    print() # ì¤„ë°”ê¿ˆ

    # [ì„¸ì…˜ ê´€ë¦¬] 40~60íšŒë§ˆë‹¤ ì„¸ì…˜ ë¬¼ê°ˆì´ (ì¶”ì  íšŒí”¼)
    if idx > start_index and idx % random.randint(40, 60) == 0:
        print("\nğŸ”„ [System] ë¸Œë¼ìš°ì € ì„¸ì…˜ ìƒˆë¡œê³ ì¹¨...")
        time.sleep(random.uniform(3, 5))
        session = create_session()

    print(f"[{idx+1}/{len(goods_ids)}] ID:{gid} ìš”ì²­ ì¤‘...", end=" ")

    try:
        url = f"https://www.musinsa.com/products/{gid}"
        
        # -------------------------------------------------------
        # STEP 1: ë©”ì¸ í˜ì´ì§€ ìš”ì²­ (Next.js ë°ì´í„° í™•ë³´)
        # -------------------------------------------------------
        response = session.get(url, timeout=10)
        
        # HTTP ì—ëŸ¬ í•¸ë“¤ë§
        if response.status_code != 200:
            print(f"âš ï¸ HTTP {response.status_code}", end=" ")
            if response.status_code in [429, 403]:
                print("\nğŸš¨ [Warning] ì°¨ë‹¨ ì˜ì‹¬! 3ë¶„ê°„ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
                time.sleep(180)
                session = create_session()
            continue

        soup = BeautifulSoup(response.text, "html.parser")
        
        # ë´‡ ì°¨ë‹¨ í˜ì´ì§€ ê°ì§€
        page_title = soup.title.get_text(strip=True) if soup.title else ""
        if any(k in page_title for k in ["Access Denied", "Just a moment", "Security Check"]):
            print(f"\nğŸš¨ [CRITICAL] ë´‡ ì°¨ë‹¨ í™”ë©´ ê°ì§€ë¨! 2ë¶„ ëŒ€ê¸° í›„ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            time.sleep(120)
            continue

        # __NEXT_DATA__ ì¶”ì¶œ
        next_data_tag = soup.find("script", {"id": "__NEXT_DATA__"})
        if not next_data_tag:
            print(f"âš ï¸ JSON íƒœê·¸ ì—†ìŒ", end=" ")
            continue
            
        try:
            raw_json = json.loads(next_data_tag.string)
        except json.JSONDecodeError:
            print(f"âš ï¸ JSON ë””ì½”ë”© ì‹¤íŒ¨", end=" ")
            continue

        # -------------------------------------------------------
        # STEP 2: ìƒí’ˆ ìƒì„¸ ë°ì´í„° ìœ„ì¹˜ íƒìƒ‰
        # -------------------------------------------------------
        product_info = None
        page_props = raw_json.get("props", {}).get("pageProps", {})

        # íƒìƒ‰ ê²½ë¡œ 1: props -> meta -> data (ê°€ì¥ ìµœì‹  êµ¬ì¡°)
        if "meta" in page_props and "data" in page_props["meta"]:
            candidate = page_props["meta"]["data"]
            if str(candidate.get("goodsNo", "")) == str(gid):
                product_info = candidate

        # íƒìƒ‰ ê²½ë¡œ 2: dehydratedState (êµ¬ êµ¬ì¡°)
        if not product_info:
            queries = page_props.get("dehydratedState", {}).get("queries", [])
            for query in queries:
                data_node = query.get("state", {}).get("data", {})
                if isinstance(data_node, dict):
                    # ì—¬ëŸ¬ í‚¤ íŒ¨í„´ í™•ì¸
                    if str(data_node.get("goodsNo", "")) == str(gid) or str(data_node.get("productNo", "")) == str(gid):
                        product_info = data_node; break
                    elif "product" in data_node and (str(data_node["product"].get("goodsNo", "")) == str(gid)):
                        product_info = data_node["product"]; break
                    elif "goods" in data_node and (str(data_node["goods"].get("goodsNo", "")) == str(gid)):
                        product_info = data_node["goods"]; break

        if not product_info:
            print(f"âš ï¸ ì •ë³´ ë§¤ì¹­ ì‹¤íŒ¨", end=" ")
            continue

        # -------------------------------------------------------
        # STEP 3: ë°ì´í„° ë§¤í•‘
        # -------------------------------------------------------
        # 1) ìƒí’ˆëª…
        product_name = (product_info.get("goodsNm") or product_info.get("goodsName") or product_info.get("productName") or "")
        
        # 2) ë¸Œëœë“œ
        brand_info = product_info.get("brandInfo", {})
        if isinstance(brand_info, dict) and "brandName" in brand_info:
            brand = brand_info["brandName"]
        else:
            brand = product_info.get("brandName", "") or product_info.get("brand", "")
        
        # 3) ê°€ê²©
        price_info = product_info.get("goodsPrice") or product_info.get("price") or {}
        normal_price = price_info.get("normalPrice") or price_info.get("originPrice") or 0
        sale_price = price_info.get("salePrice") or price_info.get("price") or 0
        discount = price_info.get("discountRate", 0)

        # 4) ì¹´í…Œê³ ë¦¬
        upper_category, lower_category = "", ""
        cat_obj = product_info.get("category")
        if isinstance(cat_obj, dict):
            upper_category = cat_obj.get("categoryDepth1Title", "")
            lower_category = cat_obj.get("categoryDepth2Title", "")
        if not upper_category:
            cats = product_info.get("categories", [])
            if cats:
                upper_category = cats[0].get("depth1Title", "")
                lower_category = cats[0].get("depth2Title", "")

        # 5) ì„±ë³„
        sex_data = product_info.get("sex")
        gender = 0
        if isinstance(sex_data, list):
            if "ë‚¨ì„±" in sex_data and "ì—¬ì„±" in sex_data: gender = 0
            elif "ë‚¨ì„±" in sex_data: gender = 1
            elif "ì—¬ì„±" in sex_data: gender = 2
        else:
            if sex_data in ["M", "MALE", "ë‚¨ì„±"]: gender = 1
            elif sex_data in ["F", "FEMALE", "ì—¬ì„±"]: gender = 2

        # 6) í†µê³„ (ë¦¬ë·°, í‰ì , ì¢‹ì•„ìš”)
        stat_info = (product_info.get("goodsReview") or product_info.get("goodsCount") or product_info.get("stat") or {})
        review_cnt = stat_info.get("totalCount") or stat_info.get("reviewCount") or 0
        rating = float(stat_info.get("satisfactionScore") or stat_info.get("reviewAverage") or 0.0)
        like_cnt = (product_info.get("goodsCount", {}).get("likeCount") or product_info.get("stat", {}).get("likeCount") or 0)
        cumulative = (product_info.get("cumulativeSales") or str(stat_info.get("purchaseCount", "")) or "")

        # -------------------------------------------------------
        # STEP 4: ìŠ¤íƒ€ì¼ íƒœê·¸ (API ìš”ì²­ ë°©ì‹)
        # -------------------------------------------------------
        tags_list = []
        try:
            # API ìš”ì²­ ì „ ì•„ì£¼ ì§§ì€ ë”œë ˆì´ (ê¸°ê³„ì  ì—°ì†ì„± ë°©ì§€)
            time.sleep(random.uniform(0.1, 0.3))
            
            tag_api_url = f"https://goods-detail.musinsa.com/api2/goods/{gid}/tags"
            tag_response = session.get(tag_api_url, timeout=5)
            
            if tag_response.status_code == 200:
                tag_json = tag_response.json()
                if "data" in tag_json and "tags" in tag_json["data"]:
                    tags_list = tag_json["data"]["tags"]
            else:
                # 404 ë“±ì€ íƒœê·¸ê°€ ì—†ëŠ” ìƒí’ˆì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¡°ìš©íˆ ì²˜ë¦¬
                pass

        except Exception as e:
            print(f"(íƒœê·¸Skip)", end=" ")

        final_tags_str = ','.join(tags_list)

        # ìˆ˜ì§‘ ìƒíƒœ ì¶œë ¥
        if final_tags_str:
            print(f"âœ… íƒœê·¸({len(tags_list)})", end=" ")
        else:
            print(f"âš ï¸ íƒœê·¸ì—†ìŒ", end=" ")

        # -------------------------------------------------------
        # STEP 5: DB ì €ì¥
        # -------------------------------------------------------
        size_json = "[]"
        fit_season_dict = {"í•": [], "ê³„ì ˆê°": []} 
        fit_json = json.dumps(fit_season_dict, ensure_ascii=False)

        # íŒŒë¼ë¯¸í„° ë§¤í•‘
        params = {
            "product_id": gid,
            "product_name": product_name,
            "brand": brand,
            "original_price": normal_price,
            "sale_price": sale_price,
            "upper_category": upper_category,
            "lower_category": lower_category,
            "gender": gender,
            "rating": rating,
            "wish_count": like_cnt,
            "review_count": review_cnt,
            "size_info": size_json,
            "discount_rate": discount,
            "fit_season": fit_json,
            "cumulative_sales": cumulative,
            "style": final_tags_str 
        }

        # ì¿¼ë¦¬ ì‹¤í–‰
        rds.execute(insert_sql, params)
        print(f"-> ì €ì¥ì™„ë£Œ")

    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
        time.sleep(5) # ì—ëŸ¬ ì‹œ ì ì‹œ ëŒ€ê¸°

print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")